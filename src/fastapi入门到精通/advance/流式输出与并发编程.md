下面介绍如何使用 FastAPI 实现流式输出和协程并发编程，这些技术可以帮助开发者轻松实现实时数据传输和并发任务处理，非常适合处理大文件、实时日志、或同时执行多个耗时操作。下面内容以简单易懂的方式说明核心知识点，并附上多个实际应用案例及代码示例。

## 基础流式输出

流式输出的意思是客户端可以一边接收数据、一边处理，而无需等到服务器生成所有内容后一次性发送。比如我们希望每秒发送一条数据，共发送 5 条，可以这样实现：

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import asyncio
import httpx  # 引入 httpx

app = FastAPI()

# 纯计算函数
def aaaa(i: int) -> str:
    result = i * 2  # 简单的计算示例
    return f"计算结果: {result}\n"

# 包含网络请求的函数
async def bbbb(i: int) -> str:
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("https://www.example.com")  # 示例网络请求
            response.raise_for_status()  # 检查请求是否成功
            return f"网络请求成功 (任务 {i}): {response.status_code}\n"
    except httpx.HTTPStatusError as e:
        return f"网络请求失败 (任务 {i}): {e}\n"
    except httpx.RequestError as e:
        return f"网络请求错误 (任务 {i}): {e}\n"

# 异步生成器：每隔一秒产生一块数据，调用 aaaa() 和 bbbb()
async def generate_data():
    for i in range(5):
        # 调用纯计算函数
        aaaa_result = aaaa(i)
        yield f"计算结果: {aaaa_result}"

        # 调用网络请求函数
        bbbb_result = await bbbb(i)
        yield f"网络请求结果: {bbbb_result}"

        await asyncio.sleep(1)  # 模拟耗时操作

@app.get("/stream")
async def stream_data():
    return StreamingResponse(generate_data(), media_type="text/plain")

```

在这个示例中，当访问 “/stream” 接口时，客户端每秒会依次收到一条数据消息，共 5 秒完成数据传输。

## 协程并发任务执行

在实际开发中，我们常常需要同时执行多个任务，比如同时监控多个传感器、并行处理多个业务逻辑等。利用 Python 的 asyncio 和 FastAPI，可以很容易实现并发任务并实时返回每个任务的进度。下面代码演示了两个并发任务执行的示例：

```python
import asyncio
from fastapi import FastAPI
from fastapi.responses import StreamingResponse

app = FastAPI()

# 第一个任务: 每 2 秒输出一条，共 3 条记录
async def task1(queue):
    for i in range(3):
        await queue.put(f"任务 1：第 {i+1} 步完成\n")
        await asyncio.sleep(2)

# 第二个任务: 每 3 秒输出一条，共 3 条记录
async def task2(queue):
    for i in range(3):
        await queue.put(f"任务 2：第 {i+1} 步完成\n")
        await asyncio.sleep(3)

# 协程生成器：从队列中读取数据并传输
async def concurrent_data_generator():
    queue = asyncio.Queue()
    tasks = [
        asyncio.create_task(task1(queue)),
        asyncio.create_task(task2(queue))
    ]
    
    # 当所有任务未完成或队列中仍有数据时，持续获取并发送数据
    while not all(task.done() for task in tasks) or not queue.empty():
        data = await queue.get()
        yield data

    # 等待所有任务结束，确保没有遗漏数据
    await asyncio.gather(*tasks)

@app.get("/concurrent_stream")
async def concurrent_stream_data():
    return StreamingResponse(concurrent_data_generator(), media_type="text/plain")
```

这个示例中有两个并发任务，其中任务 1 每 2 秒完成一小步，总共耗时约 6 秒；任务 2 每 3 秒完成一小步，总共耗时约 9 秒。最终接口 “/concurrent_stream” 会实时输出两个任务的执行进度，直观呈现并发执行的效果。

## 实际应用案例：异步文件下载

在实际项目中，异步读取大文件可以避免服务器阻塞，从而提高系统的响应速度。这种方式特别适用于大文件（例如几十兆甚至上百兆的文件）的下载服务。下面代码展示如何使用 aiofiles 实现异步文件读取，并通过流式响应下载文件：

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import aiofiles

app = FastAPI()

# 异步文件读取器：每次读取 1024 字节
async def async_file_reader(file_path):
    async with aiofiles.open(file_path, 'rb') as file:
        while True:
            chunk = await file.read(1024)
            if not chunk:
                break
            yield chunk

@app.get("/async_download")
async def async_download_file():
    file_path = "large_file.zip"  # 假设文件大小为 50MB 或更大
    return StreamingResponse(async_file_reader(file_path), media_type="application/octet-stream")
```

这个示例中，使用 aiofiles 异步读取文件，每次读取 1024 字节，并通过 “/async_download” 接口将数据流传输给客户端。这样，即使在文件下载过程中，服务器也能继续处理其他请求。

## 其他实际应用案例

- **实时日志监控**  
  在运维系统中，服务器不断生成日志。利用流式输出接口，可以实时推送日志给前端监控仪表盘。例如，每隔 2 秒输出最新的日志数据，让运维人员即时掌握系统运行状态。

- **多传感器数据采集**  
  对于智能家居或工业监控系统，通常会同时采集多个传感器数据。使用协程并发任务，各个传感器数据可以同时读取，并通过统一接口实时推送到监控终端，实现数据并发传输与展示。

## 使用技巧和注意事项

- **`async/await` 关键字**  
  保证异步函数的正确声明与调用，避免因阻塞导致性能瓶颈。
  
- **合理使用 `asyncio.sleep()`**  
  模拟耗时操作时使用 sleep 函数，同时确保不会长时间占用事件循环。

- **控制并发任务数**  
  在实际生产环境中，任务过多可能导致系统负载过高，可采用信号量或者队列机制限制并发数，确保系统稳定性（例如限制同时并发任务数不超过 50 个）。

通过上述示例和实际应用，你可以直观了解如何在 FastAPI 中实现流式数据传输与协程并发编程。这些技术能显著提升应用的响应能力和并发处理能力，适用于大文件下载、实时日志传输、多任务并行处理等场景。